import torch
import re
import matplotlib.pyplot as plt
import os
import cv2 as cv
import numpy as np
import torch.nn as nn
import torch.nn.functional as F

##### Dimensions #####
# Images of size (in_size, in_size) with values in the range [0, 1]
# data shape: (batch_size, in_size, in_size)
##### Dimensions #####

folder = "Cat"
# folder = "Dog"

processed_path = f"data/Processed/{folder}"
in_size = 80
num_data = 8000

device = torch.device('cuda')
np.random.seed(42)

# No used to create this one, generated by chat for funsies
class AutoencoderNonlinearV2(torch.nn.Module):
    def __init__(self, in_size=80, encoding_dim=20):
        super(AutoencoderNonlinearV2, self).__init__()
        self.in_size = in_size
        self.encoding_dim = encoding_dim
        flat_size = in_size * in_size
        encoded_size = encoding_dim * encoding_dim

        # Encoder: deeper with ReLU
        self.encoder = nn.Sequential(
            nn.Linear(flat_size, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, encoded_size)
        ).to(device)

        # Decoder: mirror of encoder
        self.decoder = nn.Sequential(
            nn.Linear(encoded_size, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, flat_size),
        ).to(device)

    def forward(self, x):
        flat = x.view(x.size(0), -1)  # flatten
        encoded = self.encoder(flat)
        decoded = self.decoder(encoded)
        decoded = decoded.view(x.size(0), self.in_size, self.in_size)  # reshape back
        return decoded

    def encoded_image(self, x):
        flat = x.view(x.size(0), -1)
        encoded = self.encoder(flat)
        return encoded.view(x.size(0), self.encoding_dim, self.encoding_dim)

class AutoencoderNonlinear(torch.nn.Module):

    def __init__(self):
        super(AutoencoderNonlinear, self).__init__()

        self.encoding_dim = 20
        self.encoder = torch.nn.Linear(in_size * in_size, self.encoding_dim * self.encoding_dim).to(device); 
        self.decoder = torch.nn.Linear(self.encoding_dim * self.encoding_dim, in_size * in_size).to(device);

    def forward(self, x):

        flat_im = torch.flatten(x, start_dim = 1, end_dim = 2)
        encoded = F.relu(self.encoder(flat_im))
        decoded = F.sigmoid(self.decoder(encoded))
        y = torch.reshape(decoded, (decoded.shape[0], in_size,in_size))

        return y

    def encoded_image(self, x):

        flat_im = torch.flatten(x, start_dim = 1, end_dim = 2)
        encoded = self.encoder(flat_im)
        y = torch.reshape(encoded, (encoded.shape[0], self.encoding_dim, self.encoding_dim))

        return y

class Autoencoder(torch.nn.Module):

    def __init__(self):
        super(Autoencoder, self).__init__()

        self.encoding_dim = 20
        self.encoder = torch.nn.Linear(in_size * in_size, self.encoding_dim * self.encoding_dim).to(device); 
        self.decoder = torch.nn.Linear(self.encoding_dim * self.encoding_dim, in_size * in_size).to(device);

    def forward(self, x):

        flat_im = torch.flatten(x, start_dim = 1, end_dim = 2)
        encoded = self.encoder(flat_im)
        decoded = self.decoder(encoded)
        y = torch.reshape(decoded, (decoded.shape[0], in_size,in_size))

        return y

    def encoded_image(self, x):

        flat_im = torch.flatten(x, start_dim = 1, end_dim = 2)
        encoded = self.encoder(flat_im)
        y = torch.reshape(encoded, (encoded.shape[0], self.encoding_dim, self.encoding_dim))

        return y

def get_data_indices() -> np.ndarray:

    indices = []

    for i in range(num_data):
        path = f"{processed_path}/{i}.jpg"
        if not os.path.isfile(path):
            continue
        indices.append(i)
    
    return np.array(indices)

data_cache = {}
batch_cache = {}

def data_loader(indices, batch_idx = None, use_data_cache = False) -> torch.Tensor:
    """Use data cache if batches are not always the same"""

    batches = len(indices)
    grayImages = torch.zeros(batches, in_size, in_size).to(device)

    if batch_idx in batch_cache and batch_idx is not None:
        return batch_cache[batch_idx]

    for i,file_idx in enumerate(indices):

        if file_idx in data_cache and use_data_cache:
            grayImages[i, :] = data_cache[file_idx]
            continue

        path = f"{processed_path}/{file_idx}.jpg"

        im = cv.imread(path)
        assert im is not None, f"File {path} does not exist"
        grayImage = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        assert grayImage.shape == (in_size, in_size), f"expected shape [{in_size}, {in_size}] got {grayImage.shape}"
        grayImage = torch.Tensor(grayImage).to(device) / 255.0

        grayImages[i, :, :] = grayImage
        data_cache[file_idx] = grayImage

    if batch_idx is not None:
        batch_cache[batch_idx] = grayImages

    return grayImages

def train(model_type):
    assert isinstance(model_type, type)
    model = model_type()

    loss_fn = torch.nn.MSELoss().to(device)
    optim = torch.optim.AdamW(model.parameters(), lr=0.001)

    MAX_EPOCHS = 5000
    indices = get_data_indices()
    real_num_data = indices.shape[0]

    num_train_data = int(real_num_data * 2.0/3.0)

    train_indices = np.random.choice(indices, num_train_data, replace = False)
    validate_indices = np.setdiff1d(indices, train_indices)

    batch_size = num_train_data

    stop = False

    for i in range(MAX_EPOCHS):
        total_train_loss = 0
        num_batches = 0
        for j in range(0, num_train_data, batch_size):
            model.train(True)
            num_batches += 1

            cur_indices = train_indices[j:j+batch_size]

            data = data_loader(cur_indices, batch_idx = j)

            if data is None:
                break

            optim.zero_grad()

            out = model(data)
            loss = loss_fn(out, data)
            total_train_loss += loss.item()
            # print(loss)

            loss.backward()
            optim.step()


        model.train(False)
        valid_data = data_loader(validate_indices, batch_idx = 'validate')
        out = model(valid_data)
        loss = loss_fn(out, valid_data)

        if i % 50 == 0 or i == 0:
            torch.save(model.state_dict(), f"model{i}.pth")

        if stop:
            break

        print(f"Epoch {i} of validation loss {(loss.item()):0.8f}, train loss {(total_train_loss/ num_batches):0.8f}")

def plot_valid_train(model_type, model_folder, write_image=False):
    assert isinstance(model_type,type), 'Model cannot be instantiated'

    model = model_type()

    loss_fn = torch.nn.MSELoss().to(device)
    indices = get_data_indices()
    real_num_data = indices.shape[0]

    num_train_data = int(real_num_data * 2.0/3.0)

    train_indices = np.random.choice(indices, num_train_data, replace = False)
    valid_indices = np.setdiff1d(indices, train_indices)
   
    i = 50
    path = f"{model_folder}/model{i}.pth"
    losses_valid = []
    losses_train = []
    iters = []
    while(os.path.isfile(path)):
        model.load_state_dict(torch.load(path, weights_only=True))
        model.eval()

        valid_data = data_loader(valid_indices, batch_idx = 'validate')
        train_data = data_loader(train_indices, batch_idx = 0)

        out_valid = model(valid_data)
        out_train = model(train_data)
        loss_valid = loss_fn(out_valid, valid_data).item()
        loss_train = loss_fn(out_train, train_data).item()
        losses_valid.append(loss_valid)
        losses_train.append(loss_train)
        iters.append(i)
        i += 50
        path = f"{model_folder}/model{i}.pth"

    plt.plot(iters, losses_valid, label='valid')
    plt.plot(iters, losses_train, label='train')
    plt.legend()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Traning vs loss')

    print(losses_valid)
    print(iters)
    if write_image:
        im_path = f"results/{model_folder}/validation_loss_curve.png"
        plt.savefig(im_path)
    else:
        plt.show()


def addtext(image, text):
    newim = cv.putText(
        image, # image on which to draw text
        text, 
        (10,10),
        cv.FONT_HERSHEY_SIMPLEX, # font to use
        0.4, # font scale
        (255, 0, 0), # color
        1, # line thickness
    )
    return newim

def to_np(im):
    return im.cpu().detach().numpy()

def plot_model_result(model: type, checkpoint_paths: list[str], write_image=False):

    assert type(checkpoint_paths) is list, 'Checkpoint_paths needs to be list of paths'
    assert len(checkpoint_paths) > 0 and type(checkpoint_paths[0]) is str, 'List needs to contains strs and be str'
    assert isinstance(model,type), 'Model cannot be instantiated'
    for i in range(len(checkpoint_paths)):
        assert os.path.isfile(checkpoint_paths[i]), f"{checkpoint_paths[i]} does not exist"

    num_models = len(checkpoint_paths)

    models = [model() for _ in range(num_models)]

    indices = get_data_indices()
    real_num_data = indices.shape[0]
    num_train_data = int(real_num_data * 2.0/3.0)

    train_indices = np.random.choice(indices, num_train_data, replace = False)
    valid_indices = np.setdiff1d(indices, train_indices)
   
    valid_data = data_loader(valid_indices, batch_idx = 'validate')
    for i in range(num_models):
        models[i].load_state_dict(torch.load(checkpoint_paths[i], weights_only=True))
        models[i].eval()

    for i in range(20):
        stacked_im = None
        for j in range(num_models):
            out_valid = models[j](valid_data)

            im = np.array(to_np(out_valid[i,:,:]))*255.0
            file_name = checkpoint_paths[j]
            reg = r'([0-9]+).pth'
            matches = re.search(reg, file_name)
            assert matches is not None
            num_epochs = matches.group(0)
            assert num_epochs != ''

            im = addtext(im, num_epochs)

            encoded_im = to_np(models[j].encoded_image(valid_data)[i,:,:])*255.0
            encoded_im = cv.resize(encoded_im, (80,80), interpolation = cv.INTER_CUBIC)

            valid_im = valid_data[i,:,:] * 255.0
            output_valid_im = np.hstack([encoded_im, im, valid_im.cpu().detach().numpy()])

            if stacked_im is None:
                stacked_im = output_valid_im
            else:
                stacked_im = np.vstack([output_valid_im, stacked_im])

        if write_image:
            im_path = f"results/{checkpoint_paths[0]}{i}.png"
            cv.imwrite(im_path, stacked_im)
        else:
            cv.imshow('cat', stacked_im.astype('uint8'))
            cv.waitKey(0)


model = Autoencoder
model = AutoencoderNonlinear
model = AutoencoderNonlinearV2

# train(model)

model_type = "lr0.001linear"
model_type = "lr0.001nonlinear"
model_type = "lr0.001nonlinearv2"

models = [4900, 4000, 2000, 1000, 400, 200, 100, 50, 0]
model_folder=f"models/{model_type}"
paths = [f"{model_folder}/model{num}.pth" for num in models]

result_path = f"results/{model_folder}"
if not os.path.isdir(result_path):
    os.makedirs(result_path)
    print(f"Created {result_path}")


plot_valid_train(model, model_folder, write_image=True)
plot_model_result(model, paths, write_image=True)
